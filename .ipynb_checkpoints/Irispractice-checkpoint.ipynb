{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, value = None, feature = None, terminal = False):\n",
    "        self.feature = feature #feature col\n",
    "        self.value = value # value at which to split at\n",
    "        self.terminal = terminal\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.categorization = \"\"\n",
    "    def __str__(self):\n",
    "        result =\"\\n\".join([\"Feature: \"+ str(self.feature),\"Value: \" + str(self.value),\"Category: \"+ str(self.categorization), \"Terminal: \" + str(self.terminal)]) \n",
    "        if self.left is not None and not self.left.terminal:\n",
    "            result = result + \"\\nLeft: Exists\" \n",
    "        else:\n",
    "            left = \"\\nLeft :Terminal\"\n",
    "            result = result + left\n",
    "\n",
    "        if self.right is not None and not self.right.terminal:\n",
    "            result = result + \"\\nRight: Exists\" \n",
    "        else:\n",
    "            right = \"\\nRight :Terminal\"\n",
    "            result = result + right\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target_col):\n",
    "    elements,counts = np.unique(target_col,return_counts = True)\n",
    "    sum = np.sum(counts)  \n",
    "    return np.sum([(-counts[i]/sum)*np.log2(counts[i]/sum) for i in range(len(elements))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split(data,features,target):\n",
    "    split = None\n",
    "    best_gain = 0\n",
    "    for x in features:\n",
    "        (max_gain, best_split) = split_for_max_gain(data, x, target)\n",
    "        print(\"Max gain for \", x, \" : \", max_gain, \"at point: \", )\n",
    "        if max_gain > best_gain:\n",
    "            best_gain = max_gain\n",
    "            split = (x,best_split)\n",
    "    return Node(split[1], split[0])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_for_max_gain(data, feature, target_name):      \n",
    "    sorted = data.sort_values(feature)\n",
    "    values = np.unique(sorted[feature])\n",
    "    splits = [(values[x] + values[x+1])/2 for x in range(len(values)-1)]\n",
    "    max_gain = 0\n",
    "    split = 0\n",
    "    for x in splits:\n",
    "        gain = info_gain_split(data, x, feature,target_name)\n",
    "        if gain > max_gain:\n",
    "            max_gain = gain\n",
    "            split = x\n",
    "    return (max_gain,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain_split(data, split_value, split_feature, target_feature):\n",
    "    \n",
    "    total_entropy = entropy(data[target_feature])\n",
    "\n",
    "    above = []\n",
    "    below = []\n",
    "\n",
    "    for x in data[split_feature]:\n",
    "        if x >= split_value:\n",
    "            above.append(x)\n",
    "        else:\n",
    "            below.append(x)\n",
    "\n",
    "    total = len(above) + len(below)\n",
    "    if(total != len(data[split_feature]):\n",
    "           input(\"FAILURE: ABOVE AND BELOW NOT WORKING\")\n",
    "    \n",
    "    entropy_above = (len(above)/total)*entropy(data.where(data[split_feature] > split_value).dropna()[target_feature])\n",
    "    entropy_below = (len(below)/total)*entropy(data.where(data[split_feature] < split_value).dropna()[target_feature])\n",
    "\n",
    "    weighted_entropy = entropy_above + entropy_below\n",
    "    return total_entropy - weighted_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_possible_splits(data, features):\n",
    "    for feature in features:\n",
    "        if(len(np.unique(data[feature])) > 1):\n",
    "            return False\n",
    "    return True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(data, originaldata, features, target):\n",
    "    \n",
    "    \n",
    "    if(no_possible_splits(data, features)):\n",
    "        node = Node(terminal=True)\n",
    "        vals, counts = np.unique(data[target], return_counts = True)\n",
    "        category_index = 0\n",
    "        for i in range(len(vals)):\n",
    "            if(counts[i] > counts[category_index]):\n",
    "                category_index = i\n",
    "        node.categorization = vals[category_index]\n",
    "        return node\n",
    "        \n",
    "        \n",
    "        #also if the target col is all one value then there is no split to be done\n",
    "    if len(np.unique(data[target])) == 1:\n",
    "        node = Node(terminal=True)\n",
    "        node.categorization = np.unique(data[target])[0]\n",
    "        return node\n",
    "    \n",
    "    root = find_split(data, features, target)\n",
    "    \n",
    "    # grabs all rows where split feautre is below\n",
    "    left_data = data.where(data[root.feature] < root.value).dropna()\n",
    "    \n",
    "    # grabs all rows where split feautre is above\n",
    "    right_data = data.where(data[root.feature] > root.value).dropna()\n",
    "    \n",
    "    \n",
    "    root.left = ID3(left_data, originaldata, features, target)\n",
    "    root.right = ID3(right_data, originaldata, features, target)\n",
    "    \n",
    "    return root\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/elidangerfield/Documents/school/CSCI4350/OLA3/iris-data.txt', sep=\" \", header=None)\n",
    "data.columns = [\"sepal_length\", \"sepal_width\", \"pedal_length\", \"pedal_width\",\"class\"]\n",
    "features = [\"sepal_length\", \"sepal_width\", \"pedal_length\", \"pedal_width\"]\n",
    "target = \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = ID3(data, data, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: pedal_length\n",
      "Value: 3.75\n",
      "Category: \n",
      "Terminal: False\n",
      "Left :Terminal\n",
      "Right: Exists\n"
     ]
    }
   ],
   "source": [
    "print(node.right.right.right.right.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNIST_CNN",
   "language": "python",
   "name": "mnist_cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
